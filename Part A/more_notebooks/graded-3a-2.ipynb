{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "158e0604",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b13636fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchsummary import summary\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam, RMSprop, SGD\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa9d35dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2860a4c6950>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for reproducibility\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "392a77f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c2f10e",
   "metadata": {},
   "source": [
    "# 1. Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f11e1537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data transforms (normalization & data augmentation)\n",
    "stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "train_tfms = transforms.Compose([transforms.RandomCrop(32, padding=4, padding_mode='reflect'), \n",
    "                         transforms.RandomHorizontalFlip(), \n",
    "                         transforms.ToTensor(), \n",
    "                         transforms.Normalize(*stats,inplace=True)])\n",
    "valid_tfms = transforms.Compose([transforms.ToTensor(), transforms.Normalize(*stats)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4aaeb52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50000, 10000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get cifar10\n",
    "train_dataset = CIFAR10(root='data', transform=train_tfms, download=True, train=True)\n",
    "val_dataset = CIFAR10(root='data', transform=valid_tfms, download=True, train=False)\n",
    "len(train_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c03afd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders\n",
    "batch_size = 256\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e33e80",
   "metadata": {},
   "source": [
    "# 2. Create a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae57e902",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifarClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, activation: str):\n",
    "        super().__init__()\n",
    "        assert activation in [\"relu\", \"sigmoid\", \"tanh\"] , \"select activation from relu, sigmoid, tanh\"\n",
    "        \n",
    "        self.activation_layer = None\n",
    "        if activation == \"relu\":\n",
    "            self.activation_layer = nn.ReLU()\n",
    "        elif activation == \"sigmoid\":\n",
    "            self.activation_layer = nn.Sigmoid()\n",
    "        elif activation == \"tanh\":\n",
    "            self.activation_layer = nn.Tanh()\n",
    "            \n",
    "        self.model = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=\"same\"),\n",
    "            self.activation_layer, \n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.16),\n",
    "\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=\"same\"),\n",
    "            self.activation_layer, \n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.16),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=\"same\"),\n",
    "            self.activation_layer, \n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.16),\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=2048, out_features=256),\n",
    "            self.activation_layer,\n",
    "            nn.Linear(in_features=256, out_features=10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a02cc606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 32, 32]             896\n",
      "              ReLU-2           [-1, 32, 32, 32]               0\n",
      "              ReLU-3           [-1, 32, 32, 32]               0\n",
      "       BatchNorm2d-4           [-1, 32, 32, 32]              64\n",
      "         MaxPool2d-5           [-1, 32, 16, 16]               0\n",
      "           Dropout-6           [-1, 32, 16, 16]               0\n",
      "            Conv2d-7           [-1, 64, 16, 16]          18,496\n",
      "              ReLU-8           [-1, 64, 16, 16]               0\n",
      "              ReLU-9           [-1, 64, 16, 16]               0\n",
      "      BatchNorm2d-10           [-1, 64, 16, 16]             128\n",
      "        MaxPool2d-11             [-1, 64, 8, 8]               0\n",
      "          Dropout-12             [-1, 64, 8, 8]               0\n",
      "           Conv2d-13            [-1, 128, 8, 8]          73,856\n",
      "             ReLU-14            [-1, 128, 8, 8]               0\n",
      "             ReLU-15            [-1, 128, 8, 8]               0\n",
      "      BatchNorm2d-16            [-1, 128, 8, 8]             256\n",
      "        MaxPool2d-17            [-1, 128, 4, 4]               0\n",
      "          Dropout-18            [-1, 128, 4, 4]               0\n",
      "          Flatten-19                 [-1, 2048]               0\n",
      "           Linear-20                  [-1, 256]         524,544\n",
      "             ReLU-21                  [-1, 256]               0\n",
      "             ReLU-22                  [-1, 256]               0\n",
      "           Linear-23                   [-1, 10]           2,570\n",
      "================================================================\n",
      "Total params: 620,810\n",
      "Trainable params: 620,810\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.99\n",
      "Params size (MB): 2.37\n",
      "Estimated Total Size (MB): 4.37\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = CifarClassifier(\"relu\").to(device)\n",
    "summary(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad36789",
   "metadata": {},
   "source": [
    "# 3. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "234e2abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create loss_fn\n",
    "loss_fn = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91b59f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create optimizer\n",
    "\n",
    "lr = 1.6 * (10**-3)\n",
    "optimizer = Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c41c2883",
   "metadata": {},
   "outputs": [],
   "source": [
    "abl_lis = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "880d8039",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6082ce840714fe9944aee22e9e0f20e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run the training loop\n",
    "from utils import train_step\n",
    "\n",
    "epochs = 32\n",
    "for epoch in tqdm(range(epochs)):\n",
    "        tres = train_step(model, train_dataloader, loss_fn, optimizer, device)\n",
    "        print(f\"epoch: {epoch}\")\n",
    "        print(f\"avg_batch_loss: {tres['avg_batch_loss']}\")\n",
    "        print(f\"time: {tres['time']}\")   \n",
    "        print(\"\")\n",
    "        abl_lis.append(tres['avg_batch_loss'].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4516b883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation\n",
    "from utils import valid_step\n",
    "\n",
    "vres = valid_step(model, val_dataloader, device)\n",
    "print(f\"accuracy: {vres['accuracy']}\")\n",
    "print(f\"confusion_matrix: \\n{vres['confusion_matrix']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d917394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg batch loss line chart\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot([i+1 for i in range(len(abl_lis))], abl_lis)\n",
    "# Set labels and title\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Avg Batch Loss')\n",
    "fig.savefig(\"relu_adam.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3b4817",
   "metadata": {},
   "source": [
    "# 4. Generalize for All Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03390282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generalize optimizers\n",
    "opt_lis = [\"adam\", \"rms\", \"sgd\"]\n",
    "\n",
    "def get_optimizer(model, opt_type):\n",
    "    if(opt_type == \"adam\"):\n",
    "        return Adam(model.parameters(), 1.6 * (10**-3))\n",
    "    elif(opt_type == \"rms\"):\n",
    "        return RMSprop(model.parameters(), 1.6 * (10**-3))\n",
    "    elif(opt_type == \"sgd\"):\n",
    "        return SGD(model.parameters(), 1.6 * (10**-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb24e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"avg_batch_loss\", exist_ok=True)\n",
    "os.makedirs(\"training_results\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caca6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_lis = [\"relu\", \"tanh\", \"sigmoid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9b42dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build generalized function\n",
    "\n",
    "def generalize(opt_type, act_type):\n",
    "    model = CifarClassifier(activation=act_type).to(device)\n",
    "    loss_fn = CrossEntropyLoss()\n",
    "    optimizer = get_optimizer(model, opt_type)\n",
    "    epochs = 32\n",
    "    file_str = \"\"\n",
    "    abl_lis = []\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        tres = train_step(model, train_dataloader, loss_fn, optimizer, device)\n",
    "        print(f\"epoch: {epoch}\")\n",
    "        print(f\"avg_batch_loss: {tres['avg_batch_loss']}\")\n",
    "        print(f\"time: {tres['time']}\")   \n",
    "        print(\"\")\n",
    "        file_str += f\"epoch: {epoch}\\n\"\n",
    "        file_str += f\"avg_batch_loss: {tres['avg_batch_loss']}\\n\"\n",
    "        file_str += f\"time: {tres['time']}\\n\\n\"\n",
    "        abl_lis.append(tres['avg_batch_loss'].item())\n",
    "\n",
    "    # avg batch loss line chart\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot([i+1 for i in range(len(abl_lis))], abl_lis)\n",
    "    # Set labels and title\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_title('Avg Batch Loss')\n",
    "    fig.savefig(f\"avg_batch_loss/{opt_type}_{act_type}.jpg\")\n",
    "    \n",
    "    vres = valid_step(model, val_dataloader, device)\n",
    "    print(f\"accuracy: {vres['accuracy']}\")\n",
    "    print(f\"confusion_matrix: \\n{vres['confusion_matrix']}\")\n",
    "    file_str += f\"accuracy: {vres['accuracy']}\\n\"\n",
    "    file_str += f\"confusion_matrix: \\n{vres['confusion_matrix']}\\n\"\n",
    "    \n",
    "    with open(f\"training_results/{opt_type}_{act_type}.txt\", \"w\") as f:\n",
    "        f.write(file_str)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaae742b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generalize(\"adam\", \"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5959346e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for opt_type in opt_lis:\n",
    "    for act_type in act_lis:\n",
    "        generalize(opt_type, act_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
