{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "158e0604",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b13636fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchsummary import summary\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa9d35dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2002fb64390>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for reproducibility\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "392a77f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c2f10e",
   "metadata": {},
   "source": [
    "# 1. Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4aaeb52d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "CIFAR10.__init__() got an unexpected keyword argument 'shuffle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# get cifar10\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m CIFAR10(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m, transform\u001b[38;5;241m=\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mToTensor(), download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mlen\u001b[39m(dataset)\n",
      "\u001b[1;31mTypeError\u001b[0m: CIFAR10.__init__() got an unexpected keyword argument 'shuffle'"
     ]
    }
   ],
   "source": [
    "# get cifar10\n",
    "dataset = CIFAR10(root='data', transform=transforms.ToTensor(), download=True)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c03afd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the train val split\n",
    "\n",
    "# set the params\n",
    "test_ratio = 0.10\n",
    "batch_size = 1024\n",
    "\n",
    "# find the sizes\n",
    "val_size = int(test_ratio * len(dataset))\n",
    "train_size = len(dataset) - val_size\n",
    "\n",
    "# split the dataset\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# create dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e33e80",
   "metadata": {},
   "source": [
    "# 2. Create a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1b7ea97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifarClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, activation: str):\n",
    "        super().__init__()\n",
    "        assert activation in [\"relu\", \"sigmoid\", \"tanh\"] , \"select activation from relu, sigmoid, tanh\"\n",
    "        \n",
    "        self.activation_layer = None\n",
    "        if activation == \"relu\":\n",
    "            self.activation_layer = nn.ReLU()\n",
    "        elif activation == \"sigmoid\":\n",
    "            self.activation_layer = nn.Sigmoid()\n",
    "        elif activation == \"tanh\":\n",
    "            self.activation_layer = nn.Tanh()\n",
    "            \n",
    "        self.model = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=\"same\"),\n",
    "            self.activation_layer, \n",
    "            # nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=\"same\"),\n",
    "            self.activation_layer, \n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.24),\n",
    "            \n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=\"same\"),\n",
    "            self.activation_layer, \n",
    "            # nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=\"same\"),\n",
    "            self.activation_layer, \n",
    "#             nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.24),\n",
    "            \n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=\"same\"),\n",
    "            self.activation_layer, \n",
    "            # nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=\"same\"),\n",
    "            self.activation_layer, \n",
    "#             nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.24),\n",
    "            \n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=\"same\"),\n",
    "            self.activation_layer, \n",
    "            # nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=\"same\"),\n",
    "            self.activation_layer, \n",
    "#             nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.24),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=4096, out_features=256),\n",
    "            self.activation_layer,\n",
    "            nn.Linear(in_features=256, out_features=10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a02cc606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
      "              ReLU-2           [-1, 64, 32, 32]               0\n",
      "              ReLU-3           [-1, 64, 32, 32]               0\n",
      "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
      "              ReLU-5           [-1, 64, 32, 32]               0\n",
      "              ReLU-6           [-1, 64, 32, 32]               0\n",
      "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
      "           Dropout-8           [-1, 64, 16, 16]               0\n",
      "            Conv2d-9          [-1, 128, 16, 16]          73,856\n",
      "             ReLU-10          [-1, 128, 16, 16]               0\n",
      "             ReLU-11          [-1, 128, 16, 16]               0\n",
      "           Conv2d-12          [-1, 128, 16, 16]         147,584\n",
      "             ReLU-13          [-1, 128, 16, 16]               0\n",
      "             ReLU-14          [-1, 128, 16, 16]               0\n",
      "        MaxPool2d-15            [-1, 128, 8, 8]               0\n",
      "          Dropout-16            [-1, 128, 8, 8]               0\n",
      "           Conv2d-17            [-1, 256, 8, 8]         295,168\n",
      "             ReLU-18            [-1, 256, 8, 8]               0\n",
      "             ReLU-19            [-1, 256, 8, 8]               0\n",
      "           Conv2d-20            [-1, 256, 8, 8]         590,080\n",
      "             ReLU-21            [-1, 256, 8, 8]               0\n",
      "             ReLU-22            [-1, 256, 8, 8]               0\n",
      "        MaxPool2d-23            [-1, 256, 4, 4]               0\n",
      "          Dropout-24            [-1, 256, 4, 4]               0\n",
      "          Flatten-25                 [-1, 4096]               0\n",
      "           Linear-26                  [-1, 256]       1,048,832\n",
      "             ReLU-27                  [-1, 256]               0\n",
      "             ReLU-28                  [-1, 256]               0\n",
      "           Linear-29                   [-1, 10]           2,570\n",
      "================================================================\n",
      "Total params: 2,196,810\n",
      "Trainable params: 2,196,810\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 5.72\n",
      "Params size (MB): 8.38\n",
      "Estimated Total Size (MB): 14.12\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = CifarClassifier(\"relu\").to(device)\n",
    "summary(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad36789",
   "metadata": {},
   "source": [
    "# 3. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "234e2abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create loss_fn\n",
    "loss_fn = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91b59f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create optimizer\n",
    "\n",
    "lr = 3.2 * (10**-4)\n",
    "optimizer = Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "880d8039",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ba9fc7965b341c3abfe02969ed7cf2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "avg_batch_loss: 2.132908582687378\n",
      "time: 27758.018732070923\n",
      "\n",
      "epoch: 1\n",
      "avg_batch_loss: 1.8292808532714844\n",
      "time: 27241.322994232178\n",
      "\n",
      "epoch: 2\n",
      "avg_batch_loss: 1.6173372268676758\n",
      "time: 27199.805736541748\n",
      "\n",
      "epoch: 3\n",
      "avg_batch_loss: 1.5109660625457764\n",
      "time: 27285.918474197388\n",
      "\n",
      "epoch: 4\n",
      "avg_batch_loss: 1.4247936010360718\n",
      "time: 27415.27223587036\n",
      "\n",
      "epoch: 5\n",
      "avg_batch_loss: 1.3605000972747803\n",
      "time: 27372.832775115967\n",
      "\n",
      "epoch: 6\n",
      "avg_batch_loss: 1.3015085458755493\n",
      "time: 27382.23886489868\n",
      "\n",
      "epoch: 7\n",
      "avg_batch_loss: 1.2535165548324585\n",
      "time: 27410.678148269653\n",
      "\n",
      "epoch: 8\n",
      "avg_batch_loss: 1.205361008644104\n",
      "time: 27383.683919906616\n",
      "\n",
      "epoch: 9\n",
      "avg_batch_loss: 1.1534439325332642\n",
      "time: 27382.514238357544\n",
      "\n",
      "epoch: 10\n",
      "avg_batch_loss: 1.1074875593185425\n",
      "time: 27406.677961349487\n",
      "\n",
      "epoch: 11\n",
      "avg_batch_loss: 1.0709277391433716\n",
      "time: 27415.08412361145\n",
      "\n",
      "epoch: 12\n",
      "avg_batch_loss: 1.0279995203018188\n",
      "time: 27326.87520980835\n",
      "\n",
      "epoch: 13\n",
      "avg_batch_loss: 0.9931640625\n",
      "time: 27350.841999053955\n",
      "\n",
      "epoch: 14\n",
      "avg_batch_loss: 0.9586277008056641\n",
      "time: 27387.237071990967\n",
      "\n",
      "epoch: 15\n",
      "avg_batch_loss: 0.9342015981674194\n",
      "time: 27347.110509872437\n",
      "\n",
      "epoch: 16\n",
      "avg_batch_loss: 0.904011607170105\n",
      "time: 27273.66876602173\n",
      "\n",
      "epoch: 17\n",
      "avg_batch_loss: 0.863580584526062\n",
      "time: 27248.053550720215\n",
      "\n",
      "epoch: 18\n",
      "avg_batch_loss: 0.8372859358787537\n",
      "time: 27191.26057624817\n",
      "\n",
      "epoch: 19\n",
      "avg_batch_loss: 0.8189326524734497\n",
      "time: 27208.44030380249\n",
      "\n",
      "epoch: 20\n",
      "avg_batch_loss: 0.7946318984031677\n",
      "time: 27272.371292114258\n",
      "\n",
      "epoch: 21\n",
      "avg_batch_loss: 0.7571834325790405\n",
      "time: 27294.47841644287\n",
      "\n",
      "epoch: 22\n",
      "avg_batch_loss: 0.7303862571716309\n",
      "time: 27311.749696731567\n",
      "\n",
      "epoch: 23\n",
      "avg_batch_loss: 0.6948525309562683\n",
      "time: 27277.538776397705\n",
      "\n",
      "epoch: 24\n",
      "avg_batch_loss: 0.6697050333023071\n",
      "time: 27288.489818572998\n",
      "\n",
      "epoch: 25\n",
      "avg_batch_loss: 0.647622287273407\n",
      "time: 27289.615154266357\n",
      "\n",
      "epoch: 26\n",
      "avg_batch_loss: 0.6286435127258301\n",
      "time: 27198.86350631714\n",
      "\n",
      "epoch: 27\n",
      "avg_batch_loss: 0.6248270869255066\n",
      "time: 27299.524784088135\n",
      "\n",
      "epoch: 28\n",
      "avg_batch_loss: 0.600074291229248\n",
      "time: 27346.076250076294\n",
      "\n",
      "epoch: 29\n",
      "avg_batch_loss: 0.577860951423645\n",
      "time: 27338.204860687256\n",
      "\n",
      "epoch: 30\n",
      "avg_batch_loss: 0.5637338757514954\n",
      "time: 27301.07355117798\n",
      "\n",
      "epoch: 31\n",
      "avg_batch_loss: 0.5460611581802368\n",
      "time: 27261.001110076904\n",
      "\n",
      "epoch: 32\n",
      "avg_batch_loss: 0.5145862698554993\n",
      "time: 27251.21784210205\n",
      "\n",
      "epoch: 33\n",
      "avg_batch_loss: 0.5105571150779724\n",
      "time: 27279.916763305664\n",
      "\n",
      "epoch: 34\n",
      "avg_batch_loss: 0.5009148716926575\n",
      "time: 27294.81315612793\n",
      "\n",
      "epoch: 35\n",
      "avg_batch_loss: 0.46702438592910767\n",
      "time: 27236.918687820435\n",
      "\n",
      "epoch: 36\n",
      "avg_batch_loss: 0.4369385242462158\n",
      "time: 27165.704488754272\n",
      "\n",
      "epoch: 37\n",
      "avg_batch_loss: 0.4268622100353241\n",
      "time: 27170.376539230347\n",
      "\n",
      "epoch: 38\n",
      "avg_batch_loss: 0.4237287938594818\n",
      "time: 27197.604656219482\n",
      "\n",
      "epoch: 39\n",
      "avg_batch_loss: 0.4146861433982849\n",
      "time: 27164.104461669922\n",
      "\n",
      "epoch: 40\n",
      "avg_batch_loss: 0.3873279094696045\n",
      "time: 27151.411056518555\n",
      "\n",
      "epoch: 41\n",
      "avg_batch_loss: 0.3691009283065796\n",
      "time: 27153.517723083496\n",
      "\n",
      "epoch: 42\n",
      "avg_batch_loss: 0.34601885080337524\n",
      "time: 27178.746461868286\n",
      "\n",
      "epoch: 43\n",
      "avg_batch_loss: 0.34423553943634033\n",
      "time: 27215.476751327515\n",
      "\n",
      "epoch: 44\n",
      "avg_batch_loss: 0.32054591178894043\n",
      "time: 27181.108474731445\n",
      "\n",
      "epoch: 45\n",
      "avg_batch_loss: 0.3097991347312927\n",
      "time: 27197.615385055542\n",
      "\n",
      "epoch: 46\n",
      "avg_batch_loss: 0.29378119111061096\n",
      "time: 27243.117809295654\n",
      "\n",
      "epoch: 47\n",
      "avg_batch_loss: 0.27007147669792175\n",
      "time: 27211.787939071655\n",
      "\n",
      "epoch: 48\n",
      "avg_batch_loss: 0.2696109414100647\n",
      "time: 27205.041646957397\n",
      "\n",
      "epoch: 49\n",
      "avg_batch_loss: 0.2510065734386444\n",
      "time: 27274.513006210327\n",
      "\n",
      "epoch: 50\n",
      "avg_batch_loss: 0.24684828519821167\n",
      "time: 27235.368251800537\n",
      "\n",
      "epoch: 51\n",
      "avg_batch_loss: 0.2288738191127777\n",
      "time: 27310.57095527649\n",
      "\n",
      "epoch: 52\n",
      "avg_batch_loss: 0.23705023527145386\n",
      "time: 27240.97466468811\n",
      "\n",
      "epoch: 53\n",
      "avg_batch_loss: 0.22398465871810913\n",
      "time: 27190.653562545776\n",
      "\n",
      "epoch: 54\n",
      "avg_batch_loss: 0.20112009346485138\n",
      "time: 27185.086488723755\n",
      "\n",
      "epoch: 55\n",
      "avg_batch_loss: 0.1851576268672943\n",
      "time: 27238.910675048828\n",
      "\n",
      "epoch: 56\n",
      "avg_batch_loss: 0.1702096313238144\n",
      "time: 27220.866203308105\n",
      "\n",
      "epoch: 57\n",
      "avg_batch_loss: 0.1730991154909134\n",
      "time: 27191.564321517944\n",
      "\n",
      "epoch: 58\n",
      "avg_batch_loss: 0.15704666078090668\n",
      "time: 27183.28046798706\n",
      "\n",
      "epoch: 59\n",
      "avg_batch_loss: 0.14797934889793396\n",
      "time: 27148.88048171997\n",
      "\n",
      "epoch: 60\n",
      "avg_batch_loss: 0.14785394072532654\n",
      "time: 27149.918794631958\n",
      "\n",
      "epoch: 61\n",
      "avg_batch_loss: 0.13821959495544434\n",
      "time: 27205.56616783142\n",
      "\n",
      "epoch: 62\n",
      "avg_batch_loss: 0.13459591567516327\n",
      "time: 27152.92763710022\n",
      "\n",
      "epoch: 63\n",
      "avg_batch_loss: 0.13272197544574738\n",
      "time: 27203.854084014893\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run the training loop\n",
    "from utils import train_step\n",
    "\n",
    "epochs = 64\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "        tres = train_step(model, train_dataloader, loss_fn, optimizer, device)\n",
    "        print(f\"epoch: {epoch}\")\n",
    "        print(f\"avg_batch_loss: {tres['avg_batch_loss']}\")\n",
    "        print(f\"time: {tres['time']}\")   \n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4516b883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7286\n",
      "confusion_matrix: \n",
      "[[0.79508197 0.01434426 0.02254098 0.01639344 0.01639344 0.00409836\n",
      "  0.00409836 0.02254098 0.06967213 0.03483607]\n",
      " [0.01953125 0.89257812 0.00195312 0.00195312 0.00195312 0.00585938\n",
      "  0.         0.         0.0234375  0.05273438]\n",
      " [0.07330827 0.0075188  0.58646617 0.07894737 0.07894737 0.05075188\n",
      "  0.05075188 0.04511278 0.02255639 0.0056391 ]\n",
      " [0.03609342 0.01698514 0.04670913 0.53078556 0.01910828 0.21019108\n",
      "  0.03397028 0.0403397  0.03609342 0.02972399]\n",
      " [0.02972399 0.         0.06794055 0.06369427 0.61146497 0.04458599\n",
      "  0.05095541 0.10191083 0.01698514 0.01273885]\n",
      " [0.01361868 0.00583658 0.03307393 0.12062257 0.04085603 0.65564202\n",
      "  0.04669261 0.05447471 0.02140078 0.0077821 ]\n",
      " [0.01380671 0.00394477 0.02761341 0.07100592 0.04536489 0.02366864\n",
      "  0.78106509 0.00197239 0.01577909 0.01577909]\n",
      " [0.024      0.012      0.02       0.034      0.042      0.062\n",
      "  0.014      0.766      0.008      0.018     ]\n",
      " [0.04563492 0.02579365 0.00396825 0.00595238 0.00793651 0.00595238\n",
      "  0.00396825 0.00396825 0.87698413 0.01984127]\n",
      " [0.01596806 0.11576846 0.00399202 0.01996008 0.00399202 0.01397206\n",
      "  0.01397206 0.01197605 0.02195609 0.77844311]]\n"
     ]
    }
   ],
   "source": [
    "# validation\n",
    "from utils import valid_step\n",
    "\n",
    "vres = valid_step(model, val_dataloader, device)\n",
    "print(f\"accuracy: {vres['accuracy']}\")\n",
    "print(f\"confusion_matrix: \\n{vres['confusion_matrix']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
