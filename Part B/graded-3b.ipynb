{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "# imports\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchsummary import summary\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1a4fcd2a910>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for reproducibility\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:08<00:00, 3073254.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 118867.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:02<00:00, 1607330.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get fashion mnsist\n",
    "train_dataset = FashionMNIST(\"./data\", download=True, transform=transforms.ToTensor())\n",
    "val_dataset = FashionMNIST(\"./data\", download=True, train=False, transform=transforms.ToTensor())\n",
    "len(train_dataset), len(val_dataset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T-shirt/top': 0,\n",
       " 'Trouser': 1,\n",
       " 'Pullover': 2,\n",
       " 'Dress': 3,\n",
       " 'Coat': 4,\n",
       " 'Sandal': 5,\n",
       " 'Shirt': 6,\n",
       " 'Sneaker': 7,\n",
       " 'Bag': 8,\n",
       " 'Ankle boot': 9}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mapping\n",
    "train_dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders\n",
    "batch_size = 128\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=\"same\"),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.block_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=\"same\"),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.block_3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=\"same\"),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.block_4 = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=128*3*3, out_features=64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.last_layer = nn.Linear(in_features=64, out_features=10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.block_4(self.block_3(self.block_2(self.block_1(x))))\n",
    "        activations = self.last_layer(features)\n",
    "        return (activations, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 28, 28]             320\n",
      "       BatchNorm2d-2           [-1, 32, 28, 28]              64\n",
      "              ReLU-3           [-1, 32, 28, 28]               0\n",
      "         MaxPool2d-4           [-1, 32, 14, 14]               0\n",
      "            Conv2d-5           [-1, 64, 14, 14]          18,496\n",
      "       BatchNorm2d-6           [-1, 64, 14, 14]             128\n",
      "              ReLU-7           [-1, 64, 14, 14]               0\n",
      "         MaxPool2d-8             [-1, 64, 7, 7]               0\n",
      "            Conv2d-9            [-1, 128, 7, 7]          73,856\n",
      "      BatchNorm2d-10            [-1, 128, 7, 7]             256\n",
      "             ReLU-11            [-1, 128, 7, 7]               0\n",
      "        MaxPool2d-12            [-1, 128, 3, 3]               0\n",
      "          Flatten-13                 [-1, 1152]               0\n",
      "           Linear-14                   [-1, 64]          73,792\n",
      "             ReLU-15                   [-1, 64]               0\n",
      "           Linear-16                   [-1, 10]             650\n",
      "================================================================\n",
      "Total params: 167,562\n",
      "Trainable params: 167,562\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.10\n",
      "Params size (MB): 0.64\n",
      "Estimated Total Size (MB): 1.74\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = FashionClassifier().to(device)\n",
    "summary(model, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               device: torch.device\n",
    "              ):\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = 0    \n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    for (X, y) in data_loader:\n",
    "        # send data to GPU\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # X, y = X.to(device), y.type(torch.LongTensor).to(device)\n",
    "        \n",
    "        # 1. forward pass\n",
    "        y_pred, _ = model(X)\n",
    "\n",
    "        # 2. calculate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        \n",
    "        # 3. optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 4. loss backward\n",
    "        loss.backward()\n",
    "        \n",
    "        # 5. optimizer step\n",
    "        optimizer.step()\n",
    "    \n",
    "    train_loss /= len(data_loader)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    return {\"avg_batch_loss\": train_loss, \"time\": (end_time - start_time)* 10**3}\n",
    "\n",
    "def valid_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               device: torch.device\n",
    "              ):\n",
    "    \n",
    "    # send the model to device\n",
    "    model.to(device)\n",
    "\n",
    "    # send the model in eval mode\n",
    "    model.eval()\n",
    "\n",
    "    # for confusion matrix and accuracy\n",
    "    y_true = torch.Tensor([]).to(device)\n",
    "    y_pred = torch.Tensor([]).to(device)\n",
    "\n",
    "    with torch.inference_mode(): \n",
    "        for X, y in data_loader:\n",
    "            # Send data to GPU\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            # 1. Forward pass\n",
    "            test_pred, _ = model(X)\n",
    "            \n",
    "            y_true = torch.cat((y_true, y), dim=0)\n",
    "            y_pred = torch.cat((y_pred, test_pred.argmax(axis=1)), dim=0)\n",
    "        \n",
    "        # send back to cpu\n",
    "        y_true = y_true.cpu()\n",
    "        y_pred = y_pred.cpu()\n",
    "\n",
    "        return {\"accuracy\": accuracy_score(y_true, y_pred), \"confusion_matrix\": confusion_matrix(y_true, y_pred, normalize=\"true\")}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create loss_fn\n",
    "loss_fn = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create optimizer\n",
    "\n",
    "lr = 3.2 * (10**-4)\n",
    "optimizer = Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ddb7b8adf54282b86859fe6e4e1f47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "avg_batch_loss: 0.4434037506580353\n",
      "time: 12172.55187034607\n",
      "\n",
      "epoch: 1\n",
      "avg_batch_loss: 0.267421156167984\n",
      "time: 10890.377283096313\n",
      "\n",
      "epoch: 2\n",
      "avg_batch_loss: 0.22502896189689636\n",
      "time: 10839.633703231812\n",
      "\n",
      "epoch: 3\n",
      "avg_batch_loss: 0.1948803961277008\n",
      "time: 11439.167499542236\n",
      "\n",
      "epoch: 4\n",
      "avg_batch_loss: 0.16981291770935059\n",
      "time: 11872.137546539307\n",
      "\n",
      "epoch: 5\n",
      "avg_batch_loss: 0.14761732518672943\n",
      "time: 11043.886423110962\n",
      "\n",
      "epoch: 6\n",
      "avg_batch_loss: 0.12854616343975067\n",
      "time: 11101.792097091675\n",
      "\n",
      "epoch: 7\n",
      "avg_batch_loss: 0.11301642656326294\n",
      "time: 11059.082984924316\n",
      "\n",
      "epoch: 8\n",
      "avg_batch_loss: 0.10432501137256622\n",
      "time: 11201.534271240234\n",
      "\n",
      "epoch: 9\n",
      "avg_batch_loss: 0.09881874918937683\n",
      "time: 10837.589025497437\n",
      "\n",
      "epoch: 10\n",
      "avg_batch_loss: 0.08720887452363968\n",
      "time: 11085.078716278076\n",
      "\n",
      "epoch: 11\n",
      "avg_batch_loss: 0.08123228698968887\n",
      "time: 11431.962251663208\n",
      "\n",
      "epoch: 12\n",
      "avg_batch_loss: 0.08062945306301117\n",
      "time: 11220.621347427368\n",
      "\n",
      "epoch: 13\n",
      "avg_batch_loss: 0.0734601616859436\n",
      "time: 12004.87995147705\n",
      "\n",
      "epoch: 14\n",
      "avg_batch_loss: 0.059608448296785355\n",
      "time: 12287.23430633545\n",
      "\n",
      "epoch: 15\n",
      "avg_batch_loss: 0.04565298184752464\n",
      "time: 13291.433811187744\n",
      "\n",
      "epoch: 16\n",
      "avg_batch_loss: 0.038250137120485306\n",
      "time: 13337.976694107056\n",
      "\n",
      "epoch: 17\n",
      "avg_batch_loss: 0.037966132164001465\n",
      "time: 12730.114459991455\n",
      "\n",
      "epoch: 18\n",
      "avg_batch_loss: 0.040345389395952225\n",
      "time: 12879.392862319946\n",
      "\n",
      "epoch: 19\n",
      "avg_batch_loss: 0.03976830840110779\n",
      "time: 12370.88680267334\n",
      "\n",
      "epoch: 20\n",
      "avg_batch_loss: 0.03625151887536049\n",
      "time: 12829.80489730835\n",
      "\n",
      "epoch: 21\n",
      "avg_batch_loss: 0.03406577929854393\n",
      "time: 12759.307146072388\n",
      "\n",
      "epoch: 22\n",
      "avg_batch_loss: 0.03485424071550369\n",
      "time: 12932.544708251953\n",
      "\n",
      "epoch: 23\n",
      "avg_batch_loss: 0.030848443508148193\n",
      "time: 12734.772443771362\n",
      "\n",
      "epoch: 24\n",
      "avg_batch_loss: 0.026130318641662598\n",
      "time: 12544.289350509644\n",
      "\n",
      "epoch: 25\n",
      "avg_batch_loss: 0.01957353763282299\n",
      "time: 12883.567333221436\n",
      "\n",
      "epoch: 26\n",
      "avg_batch_loss: 0.016503246501088142\n",
      "time: 12433.93325805664\n",
      "\n",
      "epoch: 27\n",
      "avg_batch_loss: 0.01496166456490755\n",
      "time: 12495.715856552124\n",
      "\n",
      "epoch: 28\n",
      "avg_batch_loss: 0.014376228675246239\n",
      "time: 12416.230201721191\n",
      "\n",
      "epoch: 29\n",
      "avg_batch_loss: 0.015254400670528412\n",
      "time: 12371.038436889648\n",
      "\n",
      "epoch: 30\n",
      "avg_batch_loss: 0.017630040645599365\n",
      "time: 12083.510398864746\n",
      "\n",
      "epoch: 31\n",
      "avg_batch_loss: 0.018719032406806946\n",
      "time: 12477.818727493286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 32\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "        tres = train_step(model, train_dataloader, loss_fn, optimizer, device)\n",
    "        print(f\"epoch: {epoch}\")\n",
    "        print(f\"avg_batch_loss: {tres['avg_batch_loss']}\")\n",
    "        print(f\"time: {tres['time']}\")   \n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9071\n",
      "confusion_matrix: \n",
      "[[0.878 0.    0.024 0.022 0.005 0.001 0.067 0.    0.003 0.   ]\n",
      " [0.005 0.974 0.001 0.009 0.005 0.    0.006 0.    0.    0.   ]\n",
      " [0.014 0.001 0.884 0.008 0.058 0.    0.035 0.    0.    0.   ]\n",
      " [0.022 0.003 0.015 0.877 0.046 0.001 0.036 0.    0.    0.   ]\n",
      " [0.002 0.    0.055 0.014 0.896 0.    0.032 0.    0.001 0.   ]\n",
      " [0.002 0.    0.    0.    0.    0.971 0.    0.02  0.    0.007]\n",
      " [0.115 0.    0.079 0.026 0.106 0.    0.67  0.    0.003 0.001]\n",
      " [0.    0.    0.    0.    0.    0.006 0.    0.968 0.    0.026]\n",
      " [0.006 0.001 0.001 0.004 0.005 0.002 0.006 0.002 0.972 0.001]\n",
      " [0.    0.    0.    0.    0.    0.003 0.001 0.015 0.    0.981]]\n"
     ]
    }
   ],
   "source": [
    "# validation results\n",
    "vres = valid_step(model, val_dataloader, device)\n",
    "print(f\"accuracy: {vres['accuracy']}\")\n",
    "print(f\"confusion_matrix: \\n{vres['confusion_matrix']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Using CNN as Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get features\n",
    "def get_features(model, data_loader):\n",
    "    # send the model to device\n",
    "    model.to(device)\n",
    "\n",
    "    # send the model in eval mode\n",
    "    model.eval()\n",
    "\n",
    "    # for confusion matrix and accuracy\n",
    "    all_y = torch.Tensor([]).to(device)\n",
    "    all_x = torch.Tensor([]).to(device)\n",
    "\n",
    "    with torch.inference_mode(): \n",
    "        for X, y in data_loader:\n",
    "            # Send data to GPU\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            # 1. Forward pass\n",
    "            _, features = model(X)\n",
    "            \n",
    "            all_y = torch.cat((all_y, y), dim=0)\n",
    "            all_x = torch.cat((all_x, features), dim=0)\n",
    "        \n",
    "        # send back to cpu\n",
    "        return (all_x.cpu(), all_y.cpu())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 64]), torch.Size([60000]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x, train_y = get_features(model, train_dataloader)\n",
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 64]), torch.Size([10000]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_x, val_y = get_features(model, val_dataloader)\n",
    "val_x.shape, val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DeepKumar_Patel\\anaconda3\\envs\\my_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# try out sklearn models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score \n",
    "\n",
    "fmodel = LogisticRegression(max_iter=256)\n",
    "fmodel.fit(train_x, train_y)\n",
    "print(\"accuracy:\", accuracy_score(val_y, fmodel.predict(val_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9132\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score \n",
    "\n",
    "fmodel = RandomForestClassifier()\n",
    "fmodel.fit(train_x, train_y)\n",
    "print(\"accuracy:\", accuracy_score(val_y, fmodel.predict(val_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9066\n"
     ]
    }
   ],
   "source": [
    "# gaussian NB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score \n",
    "\n",
    "fmodel = GaussianNB()\n",
    "fmodel.fit(train_x, train_y)\n",
    "print(\"accuracy:\", accuracy_score(val_y, fmodel.predict(val_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9086\n"
     ]
    }
   ],
   "source": [
    "# multinomial NB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score \n",
    "\n",
    "fmodel = MultinomialNB()\n",
    "fmodel.fit(train_x, train_y)\n",
    "print(\"accuracy:\", accuracy_score(val_y, fmodel.predict(val_x)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
